table(CleanData$iss_3elien_tooMuchPublicTransport)
table(CleanData$iss_3elien_accord, CleanData$source_id)
table(CleanData$iss_3elien_accordDim, CleanData$source_id)
table(CleanData$iss_3elien_tooMuchPublicTransport, CleanData$source_id)
## Environnement --------------------------------------------------------
#### iss_gvtMoreEnv
#### my_lifestyle_is_not_harmful_to_environment
#### cons_meat
#### public transport
hist(Data$iss_gvtMoreEnv)
CleanData$iss_enviro_envGvtMore <- Data$iss_gvtMoreEnv
hist(CleanData$iss_enviro_envGvtMore)
hist(Data$my_lifestyle_is_not_harmful_to_environment)
CleanData$iss_enviro_envLifestyle <- Data$my_lifestyle_is_not_harmful_to_environment
hist(CleanData$iss_enviro_envLifestyle)
CleanData$iss_enviro_envLifestyle <- finverser(CleanData$iss_enviro_envLifestyle)
Data$cons_meat <- NA
Data$cons_meat[Data$cons_meat_never == 1] <- 7
Data$cons_meat[Data$cons_meat_almost_never == 1] <- 6
Data$cons_meat[Data$cons_meat_once_month == 1] <- 5
Data$cons_meat[Data$cons_meat_once_week == 1] <- 4
Data$cons_meat[Data$cons_meat_few_week == 1] <- 3
Data$cons_meat[Data$cons_meat_daily == 1] <- 2
Data$cons_meat[Data$cons_meat_few_daily == 1] <- 1
Data$cons_meat <- clessnverse::normalize_min_max(Data$cons_meat)
hist(Data$cons_meat)
CleanData$iss_enviro_envMeat <- Data$cons_meat
hist(CleanData$iss_enviro_envMeat)
Data$public_transport <- Data$act_transport_Bicycle+Data$act_transport_PublicTransportation+Data$act_transport_Walk
hist(Data$public_transport)
CleanData$iss_enviro_envTransp <- Data$public_transport
hist(CleanData$iss_enviro_envTransp)
CleanData$political_knowledge <- NA
raw <- sondr::load_variable(file = "_SharedFolder_memoire-pot-growth/data/lake/omnibus/may/may.Sav",
variable = "C25")
table(raw)
clean <- NA
clean[raw == 1] <- 1
clean[raw == 2] <- 0.75
clean[raw == 3] <- 0.5
clean[raw == 4] <- 0.25
clean[raw == 5] <- 0
table(clean)
CleanData$political_knowledge[CleanData$source_id == "may"] <- clean
## datagotchi pilote 2 2022
##### FR_scalePol En utilisant l'échelle ci-dessous, comment évaluez-vous votre niveau de connaissances politiques?
##### EN_knowPol Using the scale below, how would you rate your level of political knowledge?
raw_fr <- sondr::load_variable(file = "_SharedFolder_memoire-pot-growth/data/lake/datagotchi_pilot2_2022/datagotchi_pilot2_2022.csv",
variable = "FR_scalePol")[-c(1, 2)]
raw_fr[raw_fr == ""] <- NA
raw_en <- sondr::load_variable(file = "_SharedFolder_memoire-pot-growth/data/lake/datagotchi_pilot2_2022/datagotchi_pilot2_2022.csv",
variable = "EN_knowPol")[-c(1, 2)]
raw_en[raw_en == ""] <- NA
raw <- as.numeric(coalesce(raw_fr, raw_en))
raw <- raw[-respondents_to_remove_pilote2]
table(raw)
clean <- NA
clean[raw == 1] <- 1
clean[raw == 4] <- 0.75
clean[raw == 5] <- 0.5
clean[raw == 6] <- 0.25
clean[raw == 7] <- 0
table(clean)
CleanData$political_knowledge[CleanData$source_id == "pilote2"] <- clean
table(CleanData$political_knowledge)
media_list <- c("RDI" = "rdi", "TVA Nouvelles" = "tva",
"Le Devoir" = "ledevoir", "La Presse" = "lapresse",
"Radio-Canada (SRC)" = "radiocan", "LCN" = "lcn",
"CTV" = "ctv", "CBC" = "cbc", "The Gazette" = "thegazette",
"Journal de Québec" = "journaldequebec",
"Journal de Montréal" = "journalmontreal", "Le Soleil" = "lesoleil",
"98.5 FM" = "fm985", "National Post" = "nationalpost",
"Globe and Mail" = "globemail", "Global News" = "globalnews",
"CNN" = "cnn", "Fox News" = "foxnews", "Guardian" = "guardian")
# Initialiser les colonnes dans CleanData
for (col_name in media_list) {
CleanData[[paste0("reception_polinfo_", col_name)]] <- NA
}
### February ----------------------------------------------------------------
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/february/february_open_clean.xlsx") %>%
select(QUEST = `{ID de fiche}`, O_C14_clean) %>%
mutate(O_C14_clean = trimws(O_C14_clean))
mediafeb <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/omnibus/february/february.Sav") %>%
select(QUEST) %>%
mutate(QUEST = as.character(QUEST)) %>%
left_join(., open, by = "QUEST")
for (media_name in names(media_list)) {
media_abb <- media_list[media_name]
column_name <- paste0("reception_polinfo_", media_abb)
CleanData[CleanData$source_id == "february", column_name] <- as.integer(grepl(media_name, mediafeb$O_C14_clean, fixed = TRUE))
}
### March ----------------------------------------------------------------
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/march/march_open_clean.xlsx") %>%
select(QUEST = `{ID de fiche}`, O_C11_clean) %>%
mutate(O_C11_clean = trimws(O_C11_clean))
mediamarch <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/omnibus/march/march.Sav") %>%
select(QUEST) %>%
mutate(QUEST = as.character(QUEST)) %>%
left_join(., open, by = "QUEST")
for (media_name in names(media_list)) {
media_abb <- media_list[media_name]
column_name <- paste0("reception_polinfo_", media_abb)
CleanData[CleanData$source_id == "march", column_name] <- as.integer(grepl(media_name, mediamarch$O_C11_clean, fixed = TRUE))
}
### April ----------------------------------------------------------------
#open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/april/april_open.xlsx") %>%
#  select(QUEST = `{ID de fiche}`, O_C11_clean) %>%
#  mutate(O_C11_clean = trimws(O_C11_clean))
#mediamarch <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/omnibus/march/march.Sav") %>%
#  select(QUEST) %>%
#  mutate(QUEST = as.character(QUEST)) %>%
#  left_join(., open, by = "QUEST")
#
#for (media_name in names(media_list)) {
#  media_abb <- media_list[media_name]
#  column_name <- paste0("polinfo_", media_abb)
#  CleanData[CleanData$source_id == "march", column_name] <- as.integer(grepl(media_name, mediamarch$O_C11_clean, fixed = TRUE))
#}
### May ---------------------------------------------------------------------
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/may/may_open_clean.xlsx") %>%
select(QUEST, O_C11_clean) %>%
mutate(O_C11_clean = trimws(O_C11_clean))
mediamay <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/omnibus/may/may.Sav") %>%
select(QUEST) %>%
mutate(QUEST = as.character(QUEST)) %>%
left_join(., open, by = "QUEST")
for (media_name in names(media_list)) {
media_abb <- media_list[media_name]
column_name <- paste0("reception_polinfo_", media_abb)
CleanData[CleanData$source_id == "may", column_name] <- as.integer(grepl(media_name, mediamay$O_C11_clean, fixed = TRUE))
}
#mediadata <- CleanData %>%
#  select(starts_with("reception_polinfo_")) %>%
#  drop_na()
#
#saveRDS(mediadata, "_SharedFolder_memoire-pot-growth/data/warehouse/media_analysis/mediadata.rds")
## Which social media ------------------------------------------------------------
code_to_social <- c(`1` = "facebook", `2` = "twitter", `3` = "instagram",
`4` = "linkedin", `5` = "tiktok", `6` = "youtube")
# Initialiser les colonnes dans CleanData
for (col_name in code_to_social) {
CleanData[[paste0("reception_socialmedia_", col_name)]] <- NA
}
### February ----------------------------------------------------------------
feb <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/omnibus/february/february.Sav") %>%
## need to be in first three choices
select(all_of(paste0("N1_M", 1:3)))
feb_transformed <- feb
for (col in names(feb_transformed)) {
feb_transformed[[col]] <- as.character(code_to_social[feb[[col]]])
}
feb_transformed$all_media <- apply(feb_transformed, 1, function(x) paste(na.omit(x), collapse = ", "))
# Créer des colonnes binaires pour chaque réseau social
for (media in code_to_social) {
column_name <- paste0("reception_socialmedia_", media)
CleanData[CleanData$source_id == "february", column_name] <- as.integer(grepl(media, feb_transformed$all_media, fixed = TRUE))
}
table(CleanData$socialmedia_tiktok, CleanData$age)
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/february/february_open_clean.xlsx") %>%
select(QUEST = `{ID de fiche}`, O_C14_clean) %>%
mutate(O_C14_clean = trimws(O_C14_clean))
mediafeb <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/omnibus/february/february.Sav") %>%
select(QUEST) %>%
mutate(QUEST = as.character(QUEST)) %>%
left_join(., open, by = "QUEST")
for (media_name in names(media_list)) {
media_abb <- media_list[media_name]
column_name <- paste0("reception_polinfo_", media_abb)
CleanData[CleanData$source_id == "february", column_name] <- as.integer(grepl(media_name, mediafeb$O_C14_clean, fixed = TRUE))
}
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/march/march_open_clean.xlsx") %>%
select(QUEST = `{ID de fiche}`, O_C11_clean) %>%
mutate(O_C11_clean = trimws(O_C11_clean))
mediamarch <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/omnibus/march/march.Sav") %>%
select(QUEST) %>%
mutate(QUEST = as.character(QUEST)) %>%
left_join(., open, by = "QUEST")
for (media_name in names(media_list)) {
media_abb <- media_list[media_name]
column_name <- paste0("reception_polinfo_", media_abb)
CleanData[CleanData$source_id == "march", column_name] <- as.integer(grepl(media_name, mediamarch$O_C11_clean, fixed = TRUE))
}
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/may/may_open_clean.xlsx") %>%
select(QUEST, O_C11_clean) %>%
mutate(O_C11_clean = trimws(O_C11_clean))
mediamay <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/omnibus/may/may.Sav") %>%
select(QUEST) %>%
mutate(QUEST = as.character(QUEST)) %>%
left_join(., open, by = "QUEST")
for (media_name in names(media_list)) {
media_abb <- media_list[media_name]
column_name <- paste0("reception_polinfo_", media_abb)
CleanData[CleanData$source_id == "may", column_name] <- as.integer(grepl(media_name, mediamay$O_C11_clean, fixed = TRUE))
}
code_to_social <- c(`1` = "facebook", `2` = "twitter", `3` = "instagram",
`4` = "linkedin", `5` = "tiktok", `6` = "youtube")
# Initialiser les colonnes dans CleanData
for (col_name in code_to_social) {
CleanData[[paste0("reception_socialmedia_", col_name)]] <- NA
}
# Initialiser les colonnes dans CleanData
for (col_name in media_list) {
CleanData[[paste0("reception_polinfo_", col_name)]] <- NA
}
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/february/february_open_clean.xlsx") %>%
select(QUEST = `{ID de fiche}`, O_C14_clean) %>%
mutate(O_C14_clean = trimws(O_C14_clean))
mediafeb <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/omnibus/february/february.Sav") %>%
select(QUEST) %>%
mutate(QUEST = as.character(QUEST)) %>%
left_join(., open, by = "QUEST")
for (media_name in names(media_list)) {
media_abb <- media_list[media_name]
column_name <- paste0("reception_polinfo_", media_abb)
CleanData[CleanData$source_id == "february", column_name] <- as.integer(grepl(media_name, mediafeb$O_C14_clean, fixed = TRUE))
}
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/march/march_open_clean.xlsx") %>%
select(QUEST = `{ID de fiche}`, O_C11_clean) %>%
mutate(O_C11_clean = trimws(O_C11_clean))
mediamarch <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/omnibus/march/march.Sav") %>%
select(QUEST) %>%
mutate(QUEST = as.character(QUEST)) %>%
left_join(., open, by = "QUEST")
for (media_name in names(media_list)) {
media_abb <- media_list[media_name]
column_name <- paste0("reception_polinfo_", media_abb)
CleanData[CleanData$source_id == "march", column_name] <- as.integer(grepl(media_name, mediamarch$O_C11_clean, fixed = TRUE))
}
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/may/may_open_clean.xlsx") %>%
select(QUEST, O_C11_clean) %>%
mutate(O_C11_clean = trimws(O_C11_clean))
mediamay <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/omnibus/may/may.Sav") %>%
select(QUEST) %>%
mutate(QUEST = as.character(QUEST)) %>%
left_join(., open, by = "QUEST")
for (media_name in names(media_list)) {
media_abb <- media_list[media_name]
column_name <- paste0("reception_polinfo_", media_abb)
CleanData[CleanData$source_id == "may", column_name] <- as.integer(grepl(media_name, mediamay$O_C11_clean, fixed = TRUE))
}
code_to_social <- c(`1` = "facebook", `2` = "twitter", `3` = "instagram",
`4` = "linkedin", `5` = "tiktok", `6` = "youtube")
# Initialiser les colonnes dans CleanData
for (col_name in code_to_social) {
CleanData[[paste0("reception_socialmedia_", col_name)]] <- NA
}
feb <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/omnibus/february/february.Sav") %>%
## need to be in first three choices
select(all_of(paste0("N1_M", 1:3)))
feb_transformed <- feb
for (col in names(feb_transformed)) {
feb_transformed[[col]] <- as.character(code_to_social[feb[[col]]])
}
feb_transformed$all_media <- apply(feb_transformed, 1, function(x) paste(na.omit(x), collapse = ", "))
# Créer des colonnes binaires pour chaque réseau social
for (media in code_to_social) {
column_name <- paste0("reception_socialmedia_", media)
CleanData[CleanData$source_id == "february", column_name] <- as.integer(grepl(media, feb_transformed$all_media, fixed = TRUE))
}
table(CleanData$socialmedia_tiktok, CleanData$age)
table(CleanData$socialmedia_tiktok)
names(CleanData)
table(CleanData$reception_socialmedia_tiktok, CleanData$age)
code_to_social <- c(`1` = "facebook", `2` = "twitter", `3` = "instagram",
`7` = "linkedin", `5` = "tiktok", `8` = "youtube")
pilote1raw <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/datagotchi_pilot1_2022/ULA12-BASE-1500.sav") %>%
slice(respondents_to_keep_pilote1) %>%
select(Q34) %>%
mutate(Q34 = code_to_social[Q34]) %>%
fastDummies::dummy_columns(., select_columns = "Q34") %>%
select(-Q34, -Q34_NA) %>%
replace_na(list("Q34_facebook" = 0,
"Q34_twitter" = 0,
"Q34_instagram" = 0,
"Q34_linkedin" = 0,
"Q34_tiktok" = 0,
"Q34_youtube" = 0))
names(pilote1raw) <- gsub("Q34_", "reception_socialmedia_", names(pilote1raw))
for (col_name in names(pilote1raw)) {
CleanData[CleanData$source_id == "pilote1", col_name] <- pilote1raw[[col_name]]
}
table(CleanData$source_id, CleanData$socialmedia_facebook)
table(CleanData$source_id, CleanData$reception_socialmedia_facebook)
names(CleanData)
table(CleanData$source_id, CleanData$reception_socialmedia_facebook)
reachfeb <- sondr::load_variable("_SharedFolder_memoire-pot-growth/data/lake/omnibus/february/february.Sav",
variable_name = "N12")
CleanData$reception_howreach <- NA
CleanData$reception_howreach[CleanData$source_id == "february" & reachfeb %in% c(1, 2, 3)] <- "direct" # poste, telephone et porte-à-porte
CleanData$reception_howreach[CleanData$source_id == "february" & reachfeb == 4] <- "tv"
CleanData$reception_howreach[CleanData$source_id == "february" & reachfeb == 5] <- "email"
CleanData$reception_howreach[CleanData$source_id == "february" & reachfeb == 6] <- "socialmedia"
CleanData$reception_howreach[CleanData$source_id == "february" & reachfeb %in% c(7, 8)] <- "journal_radio"
table(CleanData$reception_howreach)
CleanData$reception_howreach <- factor(CleanData$reception_howreach)
table(CleanData$reception_howreach)
names(CleanData)
imp_di <- missForest::missForest(Data[1:15,], verbose = TRUE)
# Packages ----------------------------------------------------------------
library(dplyr)
Data <- readRDS("_SharedFolder_memoire-pot-growth/data/warehouse/survey_data/survey_data_holes.rds") %>%
tidyr::drop_na(riding_id)
Id_data <- Data[, c("id", "source_id", "riding_id")]
Data <- Data %>% select(-c("id", "source_id", "riding_id"))
## number of iterations to do. So if iterations = 10, the dataset will be multiplied by 10.
iterations <- 10
imp_di <- missForest::missForest(Data[1:15,], verbose = TRUE)
View(imp_di)
t <- imp_di[["ximp"]]
View(t)
warnings()
di <- imp_di$ximp
## number of iterations to do. So if iterations = 10, the dataset will be multiplied by 10.
iterations <- 10
for (i in 1:iterations){
imp_di <- missForest::missForest(Data[1:15,], verbose = TRUE)
di <- imp_di$ximp
if (i == 1){
Output <- di
} else {
Output <- rbind(Output, di)
}
message(paste0("-------- ITERATION #", i , "IS DONE ------------"))
}
## number of iterations to do. So if iterations = 10, the dataset will be multiplied by 10.
iterations <- 10
for (i in 1:iterations){
imp_di <- missForest::missForest(Data[1:15,])
di <- imp_di$ximp
if (i == 1){
Output <- di
} else {
Output <- rbind(Output, di)
}
message(paste0("-------- ITERATION #", i , " IS DONE ------------"))
}
## number of iterations to do. So if iterations = 10, the dataset will be multiplied by 10.
iterations <- 10
for (i in 1:iterations){
message(paste0("-------- ITERATION #", i , " STARTING ------------"))
imp_di <- missForest::missForest(Data[1:15,])
di <- imp_di$ximp
if (i == 1){
Output <- di
} else {
Output <- rbind(Output, di)
}
message(paste0("-------- ITERATION #", i , " IS DONE ------------"))
}
## number of iterations to do. So if iterations = 10, the dataset will be multiplied by 10.
iterations <- 10
for (i in 1:iterations){
message(paste0("-------- ITERATION #", i , " STARTING ------------"))
imp_di <- missForest::missForest(Data)
di <- imp_di$ximp
if (i == 1){
Output <- di
} else {
Output <- rbind(Output, di)
}
message(paste0("-------- ITERATION #", i , " IS DONE ------------"))
}
warnings()
# Packages ----------------------------------------------------------------
library(tidyverse)
library(openai)
# Test --------------------------------------------------------------------
answers <- c(
"Vaccination covid",
"Racism and gender equality",
"Enviromental issues and animal rights",
"L'ÉCONOMIE. Mettre en valeur et développer nos ressources naturelles, incluant le pétrole et les mines, de façon responsable et respectueuse de l'environnement.",
"L’argent"
)
## Get a vector of the ids with open answers about MI issue ----------------
ids <- readRDS("_SharedFolder_memoire-pot-growth/data/warehouse/surveys.rds") %>%
filter(source_id %in% c("february", "march", "april",
"may", "pilote1", "pilote2")) %>% ## source_id with open answers about MI issue
pull(., id)
Data <- readRDS("_SharedFolder_memoire-pot-growth/data/warehouse/surveys.rds")
## ! Respondents to keep pilote 1 ----------------------------------------
## in this survey, some respondents were removed in the cleaning.
clean_survey <- sondr::read_any_csv("_SharedFolder_memoire-pot-growth/data/lake/datagotchi_pilot1_2022/Pilote1_clean.csv")
respondents_to_keep_pilote1 <- clean_survey$id ## vector containing the rows to keep
# remove unwanted df from environment
rm(clean_survey)
## ! Respondents to remove from pilote 2 -------------------------------------
all_respondents_df <- sondr::read_any_csv("_SharedFolder_memoire-pot-growth/data/lake/datagotchi_pilot2_2022/datagotchi_pilot2_2022.csv")
## this df contains all 1970 respondents of this survey, but with the RCI cleaned.
#### for the RCI
####### if the respondent has answered NA to 4 or less parties,
######### this means that the NAs should become 0.5, the default position of the slider in Qualtrics
######### (programming error in Qualtrics)
raw1 <- readRDS("_SharedFolder_memoire-pot-growth/data/lake/datagotchi_pilot2_2022/Pilote2.rds")
raw1$nas <- rowSums(is.na(raw1 %>% select(starts_with("potGrowth"))))
table(raw1$nas)
# 0 means the respondent answered for the 5 parties (nothing to do)
# 1,2,3 or 4 means the respondent answered the question but skipped some parties
##### (which means the respondent didnt change the party from the default 5 position in Qualtrics)
# 5 means the respondent didnt answer the question
### Remove respondents who didnt answer potGrowth question
respondents_to_remove_pilote2 <- which(raw1$nas==5)
## remove unwanted dataframes
rm(all_respondents_df, raw1)
## Merge open answers ------------------------------------------------------
table(Data$source_id)
rm_open_answers <- function(source_id, idvar_in_survey = "QUEST", idvar_in_open = "{ID de fiche}"){
survey_ids <- haven::read_sav(paste0("_SharedFolder_memoire-pot-growth/data/lake/omnibus/", source_id, "/", source_id, ".Sav"))[[idvar_in_survey]]
open_answers <- readxl::read_excel(paste0("_SharedFolder_memoire-pot-growth/data/lake/omnibus/", source_id, "/", source_id, "_open.xlsx"))[[idvar_in_open]]
output <- open_answers[!(open_answers %in% survey_ids)]
return(output)
}
rm_open_answers(source_id = "february",
idvar_in_survey = "QUEST",
idvar_in_open = "{ID de fiche}")
rm_open_answers(source_id = "march")
## February ----------------------------------------------------------------
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/february/february_open.xlsx")
feb_answers <- open$O_C7[!(open$`{ID de fiche}` %in% rm_open_answers("february"))]
## March -------------------------------------------------------------------
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/march/march_open.xlsx")
march_answers <- open$O_C6[!(open$`{ID de fiche}` %in% rm_open_answers("march"))]
## April -------------------------------------------------------------------
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/april/april_open.xlsx")
april_answers <- open$O_C6[!(open$QUEST %in% rm_open_answers("april", idvar_in_open = "QUEST"))]
## May -------------------------------------------------------------------
open <- readxl::read_excel("_SharedFolder_memoire-pot-growth/data/lake/omnibus/may/may_open.xlsx")
may_answers <- open$O_C6[!(open$QUEST %in% rm_open_answers("may", idvar_in_open = "QUEST"))]
## Pilote1 -----------------------------------------------------------------
pilote1_answers <- haven::read_sav("_SharedFolder_memoire-pot-growth/data/lake/datagotchi_pilot1_2022/ULA12-BASE-1500.sav")$Q83O[respondents_to_keep_pilote1]
## Pilote2 -----------------------------------------------------------------
pilote2_answers_fr <- sondr::read_any_csv("_SharedFolder_memoire-pot-growth/data/lake/datagotchi_pilot2_2022/datagotchi_pilot2_2022.csv")$FR_openFutur[-respondents_to_remove_pilote2][-c(1:2)]
pilote2_answers_fr[is.na(pilote2_answers_fr)] <- NA
pilote2_answers_en <- sondr::read_any_csv("_SharedFolder_memoire-pot-growth/data/lake/datagotchi_pilot2_2022/datagotchi_pilot2_2022.csv")$EN_openPersonally[-respondents_to_remove_pilote2][-c(1:2)]
pilote2_answers_en[is.na(pilote2_answers_en)] <- NA
pilote2_answers <- coalesce(pilote2_answers_fr, pilote2_answers_en)
rm(pilote2_answers_fr, pilote2_answers_en)
# Merge it all ------------------------------------------------------------
open_answers <- c(feb_answers, march_answers, april_answers, may_answers, pilote1_answers, pilote2_answers)
names(open_answers) <- c(Data$id[Data$source_id == "february"],
Data$id[Data$source_id == "march"],
Data$id[Data$source_id == "april"],
Data$id[Data$source_id == "may"],
Data$id[Data$source_id == "pilote1"],
Data$id[Data$source_id == "pilote2"])
k <- nrow(read.csv("_SharedFolder_memoire-pot-growth/data/warehouse/most_important_issues.csv")) + 1
for (i in k:length(open_answers)){
answeri <- open_answers[i]
request_successful <- FALSE
attempt_time <- 0
print(paste("Traitement de la réponse :", answeri))
while (!request_successful && attempt_time <= 5) {
start_time <- Sys.time()
chat_prompt <- tryCatch({
R.utils::withTimeout({
create_chat_completion(
model = "gpt-4",
messages = list(
list(
"role" = "system",
"content" = "You are a helpful assistant trained to assist in categorizing open answers about Quebecers' most important political issues into R comprehensible vectors.
I have 10 issues to categorize: (1) Quebec's sovereignty/nationalism, (2) the protection of the French language in Quebec, (3) state secularism (laicite), (4) quebec immigration laws,
(5) new left attitudes (systemic racism, transgender, social rights, etc.), (6) libertrian attitudes (included whatever related to anything in link to how COVID-19 restrained liberties),
(7) 3rd transport link between Quebec and Lévis (8) the environment, (9) economic and (10) health system or personal health issues (not COVID related).
I want you to return me a vector containing 8 values between 0, 0.5 and 1, one value for each issue, where 0 = not at all important, 0.5 = somewhat important and 1 = very important.
I want a vector like this as the output AND NOTHING ELSE: 'c(nationalisme = 1, lang = 0.5, laic = 0.5, immig = 0, newleft = 0.5, liberty = 1, lien3 = 0, enviro = 0, economy = 0, health = 0)'.
If you don't understand the open answer or whatever, still return this vector with 0 values everywhere.
If I give you '...' or 'NA' or anything that's not comprehensible, return this vector with 0 values everywhere.
Respondents were asked: 'What is the most important issue for you personnally?'
So for example, if the open answer of a respondent is 'Abbolition passeport vaccinal', I want this as the output:
c(nationalisme = 0, lang = 0, laic = 0, immig = 0, newleft = 0, liberty = 1, lien3 = 0, enviro = 0, economy = 0, health = 0).
Other example, if the open answer of a respondent is 'La crise climatique', I want this as the output:
c(nationalisme = 0, lang = 0, laic = 0, immig = 0, newleft = 0, liberty = 0, lien3 = 0, enviro = 1, economy = 0, health = 0).
Other example, if the open answer of a respondent is '...' or 'NA', I want this as the output:
c(nationalisme = 0, lang = 0, laic = 0, immig = 0, newleft = 0, liberty = 0, lien3 = 0, enviro = 0, economy = 0, health = 0)
"),
list(
"role" = "user",
"content" = paste0("Output the vector of categorized issues for this answer: ", answeri, ".")
)
)
)
}, timeout = 10)  # Timeout en secondes
}, error = function(e) {
cat("Erreur ou timeout pour la réponse :", i, "-", answeri, "\n")
NULL  # En cas d'erreur ou de timeout, retourne NULL
})
end_time <- Sys.time()
attempt_time <- as.numeric(end_time - start_time, units = "secs")
if (!is.null(chat_prompt)) {
request_successful <- TRUE
cat("Réponse obtenue avec succès pour :", i, "-", answeri, "\n")
vector <- eval(parse(text = chat_prompt$choices$message.content))
message(paste0(answeri, " ==> "))
print(vector)
if (i == 1){
write.table(data.frame(id = names(answeri), t(vector)),
"_SharedFolder_memoire-pot-growth/data/warehouse/most_important_issues.csv",
row.names = FALSE, sep = ",")
} else {
write.table(data.frame(id = names(answeri), t(vector)),
"_SharedFolder_memoire-pot-growth/data/warehouse/most_important_issues.csv",
append = TRUE, col.names = FALSE, row.names = FALSE,
sep = ",")
}
} else {
cat("Tentative échouée, nouvelle tentative pour :", i, "-", answeri, "\n")
Sys.sleep(1)  # Petite pause avant de réessayer
}
}
}
usethis::edit_r_environ()
